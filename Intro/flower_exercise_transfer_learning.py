# -*- coding: utf-8 -*-
"""Flower_Exercise_Transfer_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FdoX2OQB_ezAbm2auejY1DQrkoFfrd_0
"""

import tensorflow as tf
import matplotlib.pylab as plt
import numpy as np
import pandas as pd
import tensorflow_hub as hub
import tensorflow_datasets as tfds
import os
import datetime

import keras
from tensorflow.keras import layers

import PIL.Image as Image

"""# Import flower dataset and split training data"""

(training_set,validation_set), dataset_info= tfds.load(
    "tf_flowers",
    with_info = True,
    as_supervised = True,
    split=['train[:70%]','train[70%:]'],
)

num_examples = dataset_info.splits['train'].num_examples
num_classes = dataset_info.features['label'].num_classes

print("Total Number of Classes: {}".format(num_classes))
print("Total number of Training Images : {}".format(num_examples))

for i, example in enumerate(training_set.take(5)):
  print('Image {} shape: {} label: {}'.format(i+1, example[0].shape, example[1]))

"""# Reformat Images and create data batches"""

IMAGE_RES = 224
BATCH_SIZE = 32

def format_image(image, label):
  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0
  return image, label

"""# Setup train and validation batches

"""

train_batches      = training_set.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)
validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)

KERAS_URL = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"

feature_extractor = hub.KerasLayer(KERAS_URL,
                                   input_shape=(IMAGE_RES, IMAGE_RES,3))

image_batch, label_batch = next(iter(train_batches.take(1)))
image_batch = image_batch.numpy()
label_batch = label_batch.numpy()

feature_batch = feature_extractor(image_batch)
print(feature_batch.shape)

feature_extractor.trainable = False
# Setup false trainable in order to only train on your layers

"""# Attach a classification Head"""

model = tf.keras.Sequential([
  feature_extractor,
  layers.Dense(5,activation='relu'),
  layers.Dense(5),
])

model.summary()

"""# Train the model"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# EPOCHS = 100
# 
# model.compile(optimizer='adam',
#               loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
#               metrics= ['accuracy'])
# 
# early_callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3)
# 
# 
# history = model.fit(train_batches,
#                     epochs=EPOCHS,
#                     validation_data=validation_batches,
#                     callbacks = [early_callbacks])

def show_model_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    epochs_range = range(len(acc))

    print("Maximum training accuracy: ",max(acc))
    print("Maximum validation accuracy: ",max(val_acc))

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    plt.figure(figsize=(10,10))
    plt.subplot(1,2,1)
    plt.plot(epochs_range,acc,label="Training accuracy")
    plt.plot(epochs_range,val_acc,label="Validation accuracy")
    plt.legend("lower right ")
    plt.title("Training and Validation accuracy")

    plt.subplot(1,2,2)
    plt.plot(epochs_range,loss,label="Training loss")
    plt.plot(epochs_range,val_loss,label="Validation loss")
    plt.legend("upper right")
    plt.title("Training and Validation loss")

    plt.show()

show_model_history(history)

class_names = np.array(dataset_info.features['label'].names)
class_names

"""# View and plot predictions"""

predicted_batch = model.predict(image_batch)
predicted_batch = tf.squeeze(predicted_batch).numpy()
predicted_ids = np.argmax(predicted_batch,axis=-1)
predicted_class_names = class_names[predicted_ids]
predicted_class_names

print("Labels:",label_batch)
print("Predicted labels:",predicted_ids)

plt.figure(figsize=(10,10))

for n in range(30):
  plt.subplot(6,5,n+1)
  plt.subplots_adjust(hspace = 0.3)
  plt.imshow(image_batch[n])
  color = 'green' if predicted_ids[n] == label_batch[n] else 'red'
  plt.title(predicted_class_names[n].title(),color=color)
  plt.axis('off')
  _=plt.suptitle('Model predictions')

"""# Now lets try compiling and fitting the model with `https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4`
* The inception model accepts 299 299 3 image sizes

# Lets make the images 299 299 3
"""

IMAGE_RES = 299

def format_image_inception(image, label):
  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0
  return image, label

"""### Setup train and validation batches with 299 299 3 size"""

train_batches      = training_set.shuffle(num_examples//4).map(format_image_inception).batch(BATCH_SIZE).prefetch(1)
validation_batches = validation_set.map(format_image_inception).batch(BATCH_SIZE).prefetch(1)

KERAS_URL = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'

feature_extractor = hub.KerasLayer(KERAS_URL,
                                   input_shape=(IMAGE_RES,IMAGE_RES,3),
                                   trainable = False)

model = tf.keras.Sequential([
        feature_extractor,
        layers.Dense(5,activation="relu"),
        layers.Dense(5),
])

model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# model.compile(
#   optimizer='adam',
#   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
#   metrics=['accuracy'])
# 
# EPOCHS = 100
# 
# early_callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3)
# 
# history = model.fit(
#     train_batches,
#     epochs = EPOCHS,
#     validation_data = validation_batches,
#     callbacks= [early_callbacks]
# )

show_model_history(history)

class_names = np.array(dataset_info.features['label'].names)
class_names

predicted_batch = model.predict(image_batch)
predicted_batch = tf.squeeze(predicted_batch).numpy()
predicted_ids = np.argmax(predicted_batch, axis=-1)
predicted_class_names = class_names[predicted_ids]
predicted_class_names

print("Labesl: ",label_batch)
print("Predicted Labels: ",predicted_ids)

plt.figure(figsize=(10,9))
for n in range(30):
  plt.subplot(6,5,n+1)
  plt.subplots_adjust(hspace = 0.3)
  plt.imshow(image_batch[n])
  color = "blue" if predicted_ids[n] == label_batch[n] else "red"
  plt.title(predicted_class_names[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (blue: correct, red: incorrect)")
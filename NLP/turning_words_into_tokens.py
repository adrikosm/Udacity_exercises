# -*- coding: utf-8 -*-
"""Turning_words_into_tokens.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NAULQJo0G0FXDzUOmYaqDtnatI5Go2aC

# Imports
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tensorflow.keras.preprocessing.text import Tokenizer

"""# Sample sentences"""

sentences = [
    'My favorite food is ice cream',
    'do you like ice cream too?',
    'My dog likes ice cream!',
    "your favorite flavor of icecream is chocolate",
    "chocolate isn't good for dogs",
    "your dog, your cat, and your parrot prefer broccoli"
]

"""# Tokenizing the words"""

tokenizer = Tokenizer(num_words = len(sentences),oov_token="<OOV>")
tokenizer.fit_on_texts(sentences)

"""# View the word index"""

# Examine the word index
word_index = tokenizer.word_index
print(word_index)

"""# Create sequences for the sentences"""

sequences = tokenizer.texts_to_sequences(sentences)
print(sequences)

sentences2 = ["I like hot chocolate",
              "My dogs and my hedgehog like kibble but my squirrel prefers grapes and my chickens like ice cream, preferably vanilla"]

sequences2 = tokenizer.texts_to_sequences(sentences2)
print(sequences2)


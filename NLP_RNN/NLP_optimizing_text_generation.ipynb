{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_optimizing_text_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOsvrkzLnrAN"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN5z5C8snlj2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amfNwz1WoBuB"
      },
      "source": [
        "# Get the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdrCOQrVoKNV",
        "outputId": "6d2ebb75-0611-4919-f72c-891f2220062c"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-03 21:49:02--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.65.78, 2607:f8b0:4004:832::200e\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.65.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jjo7ka6mj48jhvcnhccs1erh47rffic8/1617486525000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-04-03 21:49:04--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jjo7ka6mj48jhvcnhccs1erh47rffic8/1617486525000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 172.217.5.225, 2607:f8b0:4004:804::2001\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|172.217.5.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [   <=>              ]  69.08M   140MB/s    in 0.5s    \n",
            "\n",
            "2021-04-03 21:49:04 (140 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgZ94gsbr0_Z"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qnVjPskrym3"
      },
      "source": [
        "def tokenize_corpus(corpus,num_words=-1):\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIKXvOgDsPNF"
      },
      "source": [
        "def create_lyrics_corpus(dataset, field):\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfMjfUZ9tJ9r",
        "outputId": "8b6e1267-e340-4450-cd34-655315c1db40"
      },
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxqSmfvYth2j"
      },
      "source": [
        "# Create Sequence and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQMuPNQwtOav"
      },
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inXJOl2GtpAt",
        "outputId": "fec3d09b-f245-49a0-9a4e-e72bf7ac05fc"
      },
      "source": [
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s44IpgatxOI",
        "outputId": "c091bd03-7ccf-4360-de49-54aa9ab052db"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 34s 7ms/step - loss: 6.1390 - accuracy: 0.0160\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.4402 - accuracy: 0.0290\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.4063 - accuracy: 0.0382\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.3253 - accuracy: 0.0417\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.2675 - accuracy: 0.0547\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.1906 - accuracy: 0.0517\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.1219 - accuracy: 0.0445\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.0550 - accuracy: 0.0453\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.9972 - accuracy: 0.0551\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.8134 - accuracy: 0.0744\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.7743 - accuracy: 0.0840\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.7275 - accuracy: 0.0903\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5269 - accuracy: 0.1109\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5058 - accuracy: 0.1123\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.3469 - accuracy: 0.1214\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.2324 - accuracy: 0.1431\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.1494 - accuracy: 0.1704\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.0882 - accuracy: 0.1733\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.8911 - accuracy: 0.2041\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.8642 - accuracy: 0.2186\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.7416 - accuracy: 0.2232\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6360 - accuracy: 0.2351\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5703 - accuracy: 0.2589\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4822 - accuracy: 0.2675\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4191 - accuracy: 0.2965\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4098 - accuracy: 0.2985\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.3015 - accuracy: 0.3146\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2045 - accuracy: 0.3404\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1425 - accuracy: 0.3457\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9705 - accuracy: 0.4018\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9997 - accuracy: 0.3991\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9141 - accuracy: 0.3976\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9009 - accuracy: 0.4123\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8381 - accuracy: 0.4297\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.7531 - accuracy: 0.4390\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7308 - accuracy: 0.4494\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6323 - accuracy: 0.4443\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5414 - accuracy: 0.4781\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5748 - accuracy: 0.4616\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.4911 - accuracy: 0.4766\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4680 - accuracy: 0.4801\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3232 - accuracy: 0.5174\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3212 - accuracy: 0.4999\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3189 - accuracy: 0.5132\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2029 - accuracy: 0.5332\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.2376 - accuracy: 0.5144\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.1810 - accuracy: 0.5458\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0702 - accuracy: 0.5789\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1475 - accuracy: 0.5428\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0694 - accuracy: 0.5775\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9743 - accuracy: 0.6066\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9446 - accuracy: 0.6025\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9252 - accuracy: 0.6087\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9411 - accuracy: 0.5974\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8726 - accuracy: 0.6180\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.8126 - accuracy: 0.6220\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7758 - accuracy: 0.6429\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7734 - accuracy: 0.6513\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7558 - accuracy: 0.6298\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7084 - accuracy: 0.6407\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6481 - accuracy: 0.6538\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7036 - accuracy: 0.6448\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6459 - accuracy: 0.6659\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5828 - accuracy: 0.6802\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5730 - accuracy: 0.6865\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5120 - accuracy: 0.7033\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.5726 - accuracy: 0.6865\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.4670 - accuracy: 0.7169\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4494 - accuracy: 0.7174\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4222 - accuracy: 0.7209\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3677 - accuracy: 0.7286\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3620 - accuracy: 0.7349\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3586 - accuracy: 0.7371\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.3924 - accuracy: 0.7203\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.3238 - accuracy: 0.7375\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3456 - accuracy: 0.7418\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.3059 - accuracy: 0.7458\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2919 - accuracy: 0.7478\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2439 - accuracy: 0.7469\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1975 - accuracy: 0.7698\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2299 - accuracy: 0.7540\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2183 - accuracy: 0.7679\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1100 - accuracy: 0.7929\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1210 - accuracy: 0.7831\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1281 - accuracy: 0.7693\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1587 - accuracy: 0.7760\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1166 - accuracy: 0.7858\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0905 - accuracy: 0.7943\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0452 - accuracy: 0.8061\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0794 - accuracy: 0.7832\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0645 - accuracy: 0.7936\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0383 - accuracy: 0.8055\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0401 - accuracy: 0.7958\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0021 - accuracy: 0.8028\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9444 - accuracy: 0.8264\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9578 - accuracy: 0.8190\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9543 - accuracy: 0.8174\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9677 - accuracy: 0.8161\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9502 - accuracy: 0.8127\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9150 - accuracy: 0.8151\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8827 - accuracy: 0.8228\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8837 - accuracy: 0.8343\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8746 - accuracy: 0.8261\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8619 - accuracy: 0.8391\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9098 - accuracy: 0.8209\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9115 - accuracy: 0.8178\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8836 - accuracy: 0.8231\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8435 - accuracy: 0.8380\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9051 - accuracy: 0.8103\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8399 - accuracy: 0.8336\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7704 - accuracy: 0.8556\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8063 - accuracy: 0.8343\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7691 - accuracy: 0.8405\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7511 - accuracy: 0.8466\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7158 - accuracy: 0.8608\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7282 - accuracy: 0.8492\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7279 - accuracy: 0.8479\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7700 - accuracy: 0.8464\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6722 - accuracy: 0.8685\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6461 - accuracy: 0.8699\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6713 - accuracy: 0.8659\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6930 - accuracy: 0.8616\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6534 - accuracy: 0.8797\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6419 - accuracy: 0.8738\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6598 - accuracy: 0.8678\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6744 - accuracy: 0.8626\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6552 - accuracy: 0.8555\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6526 - accuracy: 0.8545\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6198 - accuracy: 0.8745\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6200 - accuracy: 0.8658\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6015 - accuracy: 0.8761\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6245 - accuracy: 0.8578\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6125 - accuracy: 0.8601\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6176 - accuracy: 0.8696\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6009 - accuracy: 0.8611\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5897 - accuracy: 0.8704\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5904 - accuracy: 0.8716\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5840 - accuracy: 0.8740\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6005 - accuracy: 0.8689\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6077 - accuracy: 0.8601\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5528 - accuracy: 0.8785\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5606 - accuracy: 0.8706\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5791 - accuracy: 0.8672\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5638 - accuracy: 0.8679\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5352 - accuracy: 0.8800\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.8838\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5441 - accuracy: 0.8741\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.8832\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5146 - accuracy: 0.8711\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.8835\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.8731\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.9049\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4824 - accuracy: 0.8915\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4768 - accuracy: 0.8902\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4765 - accuracy: 0.8924\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5161 - accuracy: 0.8785\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.8836\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5569 - accuracy: 0.8712\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6219 - accuracy: 0.8544\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.8779\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5674 - accuracy: 0.8569\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.8972\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5698 - accuracy: 0.8609\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.8819\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.8951\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.9005\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.8907\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.8895\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4537 - accuracy: 0.8951\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.8908\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.8839\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8983\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8978\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8906\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8914\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.9048\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8829\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.9139\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8934\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.9002\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3630 - accuracy: 0.9115\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8922\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8962\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.9051\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.8893\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3692 - accuracy: 0.9058\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.9034\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3647 - accuracy: 0.9040\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3585 - accuracy: 0.9005\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3607 - accuracy: 0.9043\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.9065\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3704 - accuracy: 0.8992\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.9065\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3610 - accuracy: 0.9078\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.9078\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3552 - accuracy: 0.9049\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3477 - accuracy: 0.9100\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.9028\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.9045\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 0.9074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyeqOH8Yt5gr"
      },
      "source": [
        "# View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJVU0Kq7t3-V"
      },
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "axaoodtpuA6p",
        "outputId": "403d3b14-9fe0-4c34-94a0-1c796970fe6e"
      },
      "source": [
        "plot_graphs(history,'accuracy')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArZ9QAI5ubIt"
      },
      "source": [
        "# Lets Generate some lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljwcr-1buXSJ",
        "outputId": "8f04e3e2-beca-4c83-987f-59df68c1edbc"
      },
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills me and the sky and shining above you would weave rain sees believe think think think think meet leaves feeling heartaches feeling loves baby be slack in our kind know am again end in end of us do do do what could i do what i do believe we must be night pavement think take am again again i think think do think think think meet future think found think learn think learn think think think think think power think dreamed am baby be leaves do believe learn do what could i do what could you do what could i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfXsUHPGueU_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
# -*- coding: utf-8 -*-
"""Flower_image_augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R0vng6ltQM0rk98O2QM5mUWeWjGdWS6w

# Flower image classification
From tensorflow example


### Import Tensorflow keras numpy pandas and matplotlib
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import logging 
import os
import glob
import shutil
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator


# Set logging level
logger = tf.get_logger()
logger.setLevel(logging.ERROR)

"""### Load data from url"""

URL = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"

zip_file = tf.keras.utils.get_file(origin=URL,
                                   fname="flower_photos.tgz",
                                   extract=True)

base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')

"""Dataset has 5 classes
* Rose
* Daisy
* Dandelion
* Sunflower
* Tulips

---
So lets create the labels for these classes

"""

classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']

"""# Lets get the flower photos"""

for flower in classes:
  img_path = os.path.join(base_dir, flower)
  images = glob.glob(img_path + '/*.jpg')
  print("{}: {} Images".format(flower, len(images)))
  num_train = int(round(len(images)*0.8))
  train, val = images[:num_train], images[num_train:]

  for t in train:
    if not os.path.exists(os.path.join(base_dir, 'train', flower)):
      os.makedirs(os.path.join(base_dir, 'train', flower))
    shutil.move(t, os.path.join(base_dir, 'train', flower))

  for v in val:
    if not os.path.exists(os.path.join(base_dir, 'val', flower)):
      os.makedirs(os.path.join(base_dir, 'val', flower))
    shutil.move(v, os.path.join(base_dir, 'val', flower))

round(len(images))

"""# Setup train and validation set"""

train_dir = os.path.join(base_dir,'train')
val_dir = os.path.join(base_dir,'val')

"""## Setup batch and image size"""

BATCH = 100
IMG_SHAPE = 150

"""# Setup function to plot images"""

def plot_images(image_array):
  fig , axes = plt.subplots(1,5,figsize=(20,20))
  axes = axes.flatten()
  for img,ax in zip(image_array,axes):
    ax.imshow(img)
  plt.tight_layout()
  plt.show()

"""### Apply rotation to images"""

image_gen = ImageDataGenerator(rescale=1./255,horizontal_flip=True)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH,
                                               directory = train_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE,IMG_SHAPE))

"""Plot out image"""

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plot_images(augmented_images)

"""### Apply random rotation"""

image_gen = ImageDataGenerator(rescale=1./255,rotation_range=45)

train_data_gen = image_gen.flow_from_directory(batch_size= BATCH,
                                               directory= train_dir,
                                               shuffle = True,
                                               target_size=(IMG_SHAPE,IMG_SHAPE))

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plot_images(augmented_images)

"""### Apply random zoom"""

image_gen = ImageDataGenerator(rescale=1./255,zoom_range=0.5)

train_data_gen = image_gen.flow_from_directory(batch_size = BATCH,
                                               directory = train_dir,
                                               shuffle = True,
                                               target_size = (IMG_SHAPE,IMG_SHAPE))

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plot_images(augmented_images)

"""# Put it all together"""

image_gen_train = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 45,
    width_shift_range = .15,
    height_shift_range = .15,
    horizontal_flip = True,
    zoom_range = 0.5
)

train_data_gen = image_gen_train.flow_from_directory(batch_size = BATCH,
                                                     directory = train_dir,
                                                     shuffle = True,
                                                     target_size = (IMG_SHAPE,IMG_SHAPE),
                                                     class_mode = 'sparse')

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plot_images(augmented_images)

"""## Create a data generaton for the validation test"""

image_gen_val = ImageDataGenerator(rescale= 1./255)

val_data_gen = image_gen_val.flow_from_directory(batch_size = BATCH,
                                                 directory = val_dir,
                                                 shuffle = True,
                                                 target_size = (IMG_SHAPE,IMG_SHAPE),
                                                 class_mode = 'sparse')

augmented_images = [val_data_gen[0][0][0] for i in range(5)]
plot_images(augmented_images)

"""# Create the CNN """

model = Sequential([
        tf.keras.layers.Conv2D(16,(3,3),  activation = 'relu',input_shape=(IMG_SHAPE,IMG_SHAPE,3)),
        tf.keras.layers.MaxPooling2D(2,2),

        tf.keras.layers.Conv2D(32, (3,3) , activation = 'relu'),
        tf.keras.layers.MaxPooling2D(2,2),

        tf.keras.layers.Conv2D(64, (3,3) , activation = 'relu'),
        tf.keras.layers.MaxPooling2D(2,2),

        tf.keras.layers.Dropout(0.2),

        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(5)
      
])

"""# Compile The model"""

model.compile(optimizer='adam',
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics= ['accuracy'])

"""# Train the model"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# EPOCHS = 100
# 
# my_callbacks = [
#     tf.keras.callbacks.EarlyStopping(patience= 4),
#     tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}--{val_loss:.2f}.h5')
# ]
# 
# my_callbacks = [
#     tf.keras.callbacks.EarlyStopping(patience = 4),
#     tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')
# ]
# 
# history = model.fit(
#     train_data_gen,
#     steps_per_epoch=int(np.ceil(train_data_gen.n / float(BATCH))),
#     epochs=EPOCHS,
#     callbacks = my_callbacks,
#     validation_data=val_data_gen,
#     validation_steps=int(np.ceil(val_data_gen.n / float(BATCH)))
# )

"""# Plot training and validation graphs"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

print("Total training accuracy :",max(acc))
print("Total validation accuracy :",max(val_acc))

epochs_range = range(len(acc))

plt.figure(figsize=(10,10))
plt.subplot(1,2,1)
plt.plot(epochs_range,acc,label='Training accuracy')
plt.plot(epochs_range,val_acc,label='Validation accuracy')
plt.legend(loc='lower right')
plt.title("Training and Validation Accuracy")

plt.subplot(1,2,2)
plt.plot(epochs_range,loss,label="Training loss")
plt.plot(epochs_range,val_loss,label="Validation loss")
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

plt.show()

